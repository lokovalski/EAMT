{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30960a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path: /Users/inaocelli/Documents/CLASSES FALL 2024/CSCI 375/Final/EAMT/data/italian_w_labels.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.abspath('data/italian_w_labels.json')\n",
    "\n",
    "filepathina = \"/Users/inaocelli/Documents/CLASSES FALL 2024/CSCI 375/Final/EAMT/data/italian_w_lables.json\"\n",
    "print(\"Absolute path:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c6e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def get_subjects_by_Q_json(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Transforms the JSON data from the input file and writes the result to the output file.\n",
    "    The output JSON uses the 'name' field from the 'answer' dictionary as keys and keeps\n",
    "    the most complete version (fewer None values) of the label for each key.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input JSON file.\n",
    "        output_file (str): Path to the output JSON file.\n",
    "    \"\"\"\n",
    "    # Helper function to count non-None values in a label\n",
    "    def count_non_none_values(label):\n",
    "        return sum(1 for value in label.values() if value is not None)\n",
    "\n",
    "    data = None\n",
    "    # Load input JSON\n",
    "    with open(input_file, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "    # Transform data\n",
    "    transformed_data = {}\n",
    "    for entry in data:\n",
    "        answer = entry['answer']\n",
    "        # print(\"this is the answer\")\n",
    "        # print(answer)\n",
    "        if answer[\"answerType\"] == 'entity' and answer[\"answer\"] != None:\n",
    "            local_answer = answer[\"answer\"]\n",
    "            #print(local_answer)\n",
    "            key = local_answer[0][\"name\"]  # Use the \"name\" field in \"answer\" dictionary as key\n",
    "            label = local_answer[0][\"label\"]\n",
    "            \n",
    "            # If the key is not in transformed_data or the current entry has more non-None fields, update the entry\n",
    "            if key not in transformed_data or count_non_none_values(label) > count_non_none_values(transformed_data[key][\"label\"]):\n",
    "                transformed_data[key] = {\n",
    "                    \"label\": label,\n",
    "                    \"mention\": entry[\"answer\"][\"mention\"],\n",
    "                    \"category\": entry[\"category\"],\n",
    "                    \"complexityType\": entry[\"complexityType\"]\n",
    "                }\n",
    "        if answer[\"answerType\"] == 'date':\n",
    "            pass\n",
    "            # maybe fill this in later if we think of something useful\n",
    "\n",
    "\n",
    "\n",
    "    # Write transformed data to output file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(transformed_data, outfile, indent=4)\n",
    "\n",
    "\n",
    "def process_jsonl_and_json(jsonl_file, json_file, output_file, include_missing = True):\n",
    "    \"\"\"\n",
    "    Processes a JSONL file and a JSON file to map entities with labels in specified languages.\n",
    "    Args:\n",
    "        jsonl_file (str): Path to the input JSONL file with the \"entities\" feature.\n",
    "        json_file (str): Path to the input JSON file with entity details.\n",
    "        output_file (str): Path to the output JSON file with modified entries.\n",
    "    \"\"\"\n",
    "    # Load the second JSON file with entity details\n",
    "    with open(json_file, 'r') as jf:\n",
    "        entity_data = json.load(jf)\n",
    "    \n",
    "    # Initialize a list for the modified JSONL entries\n",
    "    modified_entries = []\n",
    "\n",
    "    # Process the JSONL file line by line\n",
    "    cont_var = True\n",
    "    with open(jsonl_file, 'r') as jlf:\n",
    "        for line in jlf:\n",
    "            cont_var = True\n",
    "\n",
    "            # Parse the line as a dictionary\n",
    "            entry = json.loads(line)\n",
    "            \n",
    "            # Extract necessary fields\n",
    "            source_lang = entry.get(\"source_locale\")\n",
    "            target_lang = entry.get(\"target_locale\")\n",
    "            entities = entry.get(\"entities\", [])\n",
    "            \n",
    "            # Build the \"entities\" dictionary for the output\n",
    "            entities_dict = {}\n",
    "            for entity_id in entities:\n",
    "                # Check if the entity ID exists in the second JSON file\n",
    "                if entity_id in entity_data:\n",
    "                    entity_labels = entity_data[entity_id][\"label\"]\n",
    "                    \n",
    "                    # Extract the labels for the source and target languages\n",
    "                    entities_dict[entity_id] = {\n",
    "                        lang: entity_labels.get(lang)\n",
    "                        for lang in [source_lang, target_lang]\n",
    "                        if lang in entity_labels\n",
    "                    }\n",
    "                else:\n",
    "                    if include_missing:\n",
    "                        entities_dict[entity_id] = \"NA\"\n",
    "                    else:\n",
    "                        cont_var = False\n",
    "\n",
    "            if not cont_var: # break out if we encounter something we can't translate\n",
    "                continue\n",
    "            # Add the new \"entities\" dictionary to the entry\n",
    "            entry[\"entities\"] = entities_dict\n",
    "            \n",
    "            # Append the modified entry to the list\n",
    "            modified_entries.append(entry)\n",
    "\n",
    "    # Write the modified entries to the output JSON file\n",
    "    with open(output_file, 'w') as outf:\n",
    "        for entry in modified_entries:\n",
    "            outf.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "def update_source_locale(jsonl_file, new_locale, output_file):\n",
    "    \"\"\"\n",
    "    Updates the source_locale field for all elements in a JSONL file.\n",
    "\n",
    "    Args:\n",
    "        jsonl_file (str): Path to the input JSONL file.\n",
    "        new_locale (str): The new value for the source_locale field.\n",
    "        output_file (str): Path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    # Open the input JSONL file and process line by line\n",
    "    with open(jsonl_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            entry = json.loads(line)  # Parse the line as a dictionary\n",
    "            entry[\"source_locale\"] = new_locale  # Update the source_locale field\n",
    "            outfile.write(json.dumps(entry) + '\\n')  # Write the updated entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9065dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entities_mapping(file_path):\n",
    "    \"\"\"\n",
    "    Loads entities and their translations from the given JSON file.\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file containing entity mappings.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping entity IDs to their translations.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def mask_entities(text, entities, entity_mapping):\n",
    "    \"\"\"\n",
    "    Replaces named entities in the text with unique placeholders based on their category/type.\n",
    "    Args:\n",
    "        text (str): The original text.\n",
    "        entities (dict): Entities with translations and IDs.\n",
    "        entity_mapping (dict): Mapping of Q-IDs to their details.\n",
    "    Returns:\n",
    "        masked_text (str): Text with entities replaced by placeholders.\n",
    "        mapping (dict): Mapping of placeholders to original entities.\n",
    "    \"\"\"\n",
    "    masked_text = text\n",
    "    mapping = {}\n",
    "    type_counters = {}  # To track counts for each entity type\n",
    "    offset = 0  # Track character shift due to replacements\n",
    "\n",
    "    for entity_id, entity_data in entities.items():\n",
    "        entity_text = entity_data['en']  # Assume English entity text is provided\n",
    "        entity_details = entity_mapping.get(entity_id, {})\n",
    "        entity_type = entity_details.get('category', 'UNKNOWN').upper()  # Default type to 'UNKNOWN'\n",
    "\n",
    "        # Initialize the counter for this type if not already done\n",
    "        if entity_type not in type_counters:\n",
    "            type_counters[entity_type] = 1\n",
    "        else:\n",
    "            type_counters[entity_type] += 1\n",
    "\n",
    "        # Generate placeholder\n",
    "        placeholder = f\"[ENTITY_{entity_type}_{type_counters[entity_type]}]\"\n",
    "\n",
    "        # Find the entity text in the original text\n",
    "        start = text.find(entity_text)\n",
    "        if start == -1:\n",
    "            print(f\"Entity '{entity_text}' not found in text.\")\n",
    "            continue  # Skip if the entity text isn't found\n",
    "\n",
    "        end = start + len(entity_text)\n",
    "\n",
    "        # Replace entity with placeholder\n",
    "        start += offset\n",
    "        end += offset\n",
    "        masked_text = masked_text[:start] + placeholder + masked_text[end:]\n",
    "\n",
    "        # Update offset and store mapping\n",
    "        offset += len(placeholder) - len(entity_text)\n",
    "        mapping[placeholder] = {\n",
    "            \"original_text\": entity_text,\n",
    "            \"label\": entity_details.get('label', {}).get('en', 'UNKNOWN'),\n",
    "            \"id\": entity_id,\n",
    "            \"type\": entity_type\n",
    "        }\n",
    "\n",
    "    return masked_text, mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d2afe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_datapath_ina = \"/Users/inaocelli/Documents/CLASSES FALL 2024/CSCI 375/Final/EAMT/data/Q_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cd9b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Text: What year was the first book of the [ENTITY_BOOKS_1] series published?\n",
      "Mapping: {'[ENTITY_BOOKS_1]': {'original_text': 'A Song of Ice and Fire', 'label': 'A Song of Ice and Fire', 'id': 'Q45875', 'type': 'BOOKS'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(filepathina, 'r') as f:\n",
    "    examples = [json.loads(line) for line in f]\n",
    "\n",
    "entity_mapping = load_entities_mapping(q_datapath_ina)  # Update path if needed\n",
    "\n",
    "example = examples[0]\n",
    "masked_text, mapping = mask_entities(example['source'], example['entities'], entity_mapping)\n",
    "\n",
    "print(\"Masked Text:\", masked_text)\n",
    "print(\"Mapping:\", mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b933f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: {'Q45875': {'it': 'Cronache del ghiaccio e del fuoco', 'en': 'A Song of Ice and Fire'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Entities:\", example['entities'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f5a4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: What year was the first book of the A Song of Ice and Fire series published?\n",
      "Entities: {'Q45875': {'it': 'Cronache del ghiaccio e del fuoco', 'en': 'A Song of Ice and Fire'}}\n",
      "Entity ID: Q45875, Mapping in Q_data: {'label': {'en': 'A Song of Ice and Fire', 'ar': 'أغنية الجليد والنار', 'de': 'Das Lied von Eis und Feuer', 'es': 'Canción de hielo y fuego', 'fr': 'Le Trône de fer', 'hi': 'अ सॉंग ऑफ आईस एंड फायर', 'it': 'Cronache del ghiaccio e del fuoco', 'ja': '氷と炎の歌', 'pt': 'As Crônicas de Gelo e Fogo'}, 'mention': 'Game of Thrones', 'category': 'books', 'complexityType': 'comparative'}\n",
      "Masked Text: What year was the first book of the [ENTITY_BOOKS_1] series published?\n",
      "Mapping: {'[ENTITY_BOOKS_1]': {'original_text': 'A Song of Ice and Fire', 'label': 'A Song of Ice and Fire', 'id': 'Q45875', 'type': 'BOOKS'}}\n"
     ]
    }
   ],
   "source": [
    "# Debugging example and entities\n",
    "print(\"Original Text:\", example['source'])\n",
    "print(\"Entities:\", example['entities'])\n",
    "\n",
    "# Check entity mapping\n",
    "for entity_id in example['entities']:\n",
    "    print(f\"Entity ID: {entity_id}, Mapping in Q_data: {entity_mapping.get(entity_id)}\")\n",
    "\n",
    "# Run masking function\n",
    "masked_text, mapping = mask_entities(example['source'], example['entities'], entity_mapping)\n",
    "\n",
    "print(\"Masked Text:\", masked_text)\n",
    "print(\"Mapping:\", mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728204b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ca561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d979d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
