{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30f26a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute path: /Users/inaocelli/Documents/CLASSES FALL 2024/CSCI 375/Final/EAMT/data/italian_w_labels.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.abspath('data/italian_w_labels.json')\n",
    "\n",
    "filepathina = \"/Users/inaocelli/Documents/CLASSES FALL 2024/CSCI 375/Final/EAMT/data/italian_w_lables.json\"\n",
    "print(\"Absolute path:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c67ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def get_subjects_by_Q_json(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Transforms the JSON data from the input file and writes the result to the output file.\n",
    "    The output JSON uses the 'name' field from the 'answer' dictionary as keys and keeps\n",
    "    the most complete version (fewer None values) of the label for each key.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input JSON file.\n",
    "        output_file (str): Path to the output JSON file.\n",
    "    \"\"\"\n",
    "    # Helper function to count non-None values in a label\n",
    "    def count_non_none_values(label):\n",
    "        return sum(1 for value in label.values() if value is not None)\n",
    "\n",
    "    data = None\n",
    "    # Load input JSON\n",
    "    with open(input_file, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "    # Transform data\n",
    "    transformed_data = {}\n",
    "    for entry in data:\n",
    "        answer = entry['answer']\n",
    "        # print(\"this is the answer\")\n",
    "        # print(answer)\n",
    "        if answer[\"answerType\"] == 'entity' and answer[\"answer\"] != None:\n",
    "            local_answer = answer[\"answer\"]\n",
    "            #print(local_answer)\n",
    "            key = local_answer[0][\"name\"]  # Use the \"name\" field in \"answer\" dictionary as key\n",
    "            label = local_answer[0][\"label\"]\n",
    "            \n",
    "            # If the key is not in transformed_data or the current entry has more non-None fields, update the entry\n",
    "            if key not in transformed_data or count_non_none_values(label) > count_non_none_values(transformed_data[key][\"label\"]):\n",
    "                transformed_data[key] = {\n",
    "                    \"label\": label,\n",
    "                    \"mention\": entry[\"answer\"][\"mention\"],\n",
    "                    \"category\": entry[\"category\"],\n",
    "                    \"complexityType\": entry[\"complexityType\"]\n",
    "                }\n",
    "        if answer[\"answerType\"] == 'date':\n",
    "            pass\n",
    "            # maybe fill this in later if we think of something useful\n",
    "\n",
    "\n",
    "\n",
    "    # Write transformed data to output file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(transformed_data, outfile, indent=4)\n",
    "\n",
    "\n",
    "def process_jsonl_and_json(jsonl_file, json_file, output_file, include_missing = True):\n",
    "    \"\"\"\n",
    "    Processes a JSONL file and a JSON file to map entities with labels in specified languages.\n",
    "    Args:\n",
    "        jsonl_file (str): Path to the input JSONL file with the \"entities\" feature.\n",
    "        json_file (str): Path to the input JSON file with entity details.\n",
    "        output_file (str): Path to the output JSON file with modified entries.\n",
    "    \"\"\"\n",
    "    # Load the second JSON file with entity details\n",
    "    with open(json_file, 'r') as jf:\n",
    "        entity_data = json.load(jf)\n",
    "    \n",
    "    # Initialize a list for the modified JSONL entries\n",
    "    modified_entries = []\n",
    "\n",
    "    # Process the JSONL file line by line\n",
    "    cont_var = True\n",
    "    with open(jsonl_file, 'r') as jlf:\n",
    "        for line in jlf:\n",
    "            cont_var = True\n",
    "\n",
    "            # Parse the line as a dictionary\n",
    "            entry = json.loads(line)\n",
    "            \n",
    "            # Extract necessary fields\n",
    "            source_lang = entry.get(\"source_locale\")\n",
    "            target_lang = entry.get(\"target_locale\")\n",
    "            entities = entry.get(\"entities\", [])\n",
    "            \n",
    "            # Build the \"entities\" dictionary for the output\n",
    "            entities_dict = {}\n",
    "            for entity_id in entities:\n",
    "                # Check if the entity ID exists in the second JSON file\n",
    "                if entity_id in entity_data:\n",
    "                    entity_labels = entity_data[entity_id][\"label\"]\n",
    "                    \n",
    "                    # Extract the labels for the source and target languages\n",
    "                    entities_dict[entity_id] = {\n",
    "                        lang: entity_labels.get(lang)\n",
    "                        for lang in [source_lang, target_lang]\n",
    "                        if lang in entity_labels\n",
    "                    }\n",
    "                else:\n",
    "                    if include_missing:\n",
    "                        entities_dict[entity_id] = \"NA\"\n",
    "                    else:\n",
    "                        cont_var = False\n",
    "\n",
    "            if not cont_var: # break out if we encounter something we can't translate\n",
    "                continue\n",
    "            # Add the new \"entities\" dictionary to the entry\n",
    "            entry[\"entities\"] = entities_dict\n",
    "            \n",
    "            # Append the modified entry to the list\n",
    "            modified_entries.append(entry)\n",
    "\n",
    "    # Write the modified entries to the output JSON file\n",
    "    with open(output_file, 'w') as outf:\n",
    "        for entry in modified_entries:\n",
    "            outf.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "def update_source_locale(jsonl_file, new_locale, output_file):\n",
    "    \"\"\"\n",
    "    Updates the source_locale field for all elements in a JSONL file.\n",
    "\n",
    "    Args:\n",
    "        jsonl_file (str): Path to the input JSONL file.\n",
    "        new_locale (str): The new value for the source_locale field.\n",
    "        output_file (str): Path to the output JSONL file.\n",
    "    \"\"\"\n",
    "    # Open the input JSONL file and process line by line\n",
    "    with open(jsonl_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            entry = json.loads(line)  # Parse the line as a dictionary\n",
    "            entry[\"source_locale\"] = new_locale  # Update the source_locale field\n",
    "            outfile.write(json.dumps(entry) + '\\n')  # Write the updated entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4638c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entities_mapping(file_path):\n",
    "    \"\"\"\n",
    "    Loads entities and their translations from the given JSON file.\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file containing entity mappings.\n",
    "    Returns:\n",
    "        dict: A dictionary mapping entity IDs to their translations.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def mask_entities(text, entities, entity_mapping):\n",
    "    \"\"\"\n",
    "    Replaces named entities in the text with unique placeholders.\n",
    "    Args:\n",
    "        text (str): The original text.\n",
    "        entities (dict): Entity dictionary with Q-IDs and their spans.\n",
    "        entity_mapping (dict): Mapping of Q-IDs to their translations.\n",
    "    Returns:\n",
    "        masked_text (str): Text with entities replaced by placeholders.\n",
    "        mapping (dict): Mapping of placeholders to original entities.\n",
    "    \"\"\"\n",
    "    masked_text = text\n",
    "    mapping = {}\n",
    "    offset = 0\n",
    "\n",
    "    for i, (entity_id, entity_data) in enumerate(entities.items()):\n",
    "        entity_text = entity_mapping.get(entity_id, {}).get('en', '')\n",
    "        if not entity_text:\n",
    "            continue  # Skip if no English translation is found\n",
    "\n",
    "        placeholder = f\"[ENTITY_{entity_id}_{i + 1}]\"\n",
    "        start = entity_data['start'] + offset\n",
    "        end = entity_data['end'] + offset\n",
    "        masked_text = masked_text[:start] + placeholder + masked_text[end:]\n",
    "        \n",
    "        # Adjust offset due to placeholder length\n",
    "        offset += len(placeholder) - len(entity_text)\n",
    "        \n",
    "        # Store mapping\n",
    "        mapping[placeholder] = {\"original_text\": entity_text, \"id\": entity_id}\n",
    "\n",
    "    return masked_text, mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_datapath_ina = \"/Users/inaocelli/Documents/CLASSES FALL 2024/CSCI 375/Final/EAMT/data/Q_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a996ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Q_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepathina, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     examples \u001b[38;5;241m=\u001b[39m [json\u001b[38;5;241m.\u001b[39mloads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[0;32m----> 6\u001b[0m entity_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mload_entities_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ_data.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update path if needed\u001b[39;00m\n\u001b[1;32m      8\u001b[0m example \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m masked_text, mapping \u001b[38;5;241m=\u001b[39m mask_entities(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m], example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m'\u001b[39m], entity_mapping)\n",
      "Cell \u001b[0;32mIn [12], line 9\u001b[0m, in \u001b[0;36mload_entities_mapping\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_entities_mapping\u001b[39m(file_path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Loads entities and their translations from the given JSON file.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m        dict: A dictionary mapping entity IDs to their translations.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Q_data.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(filepathina, 'r') as f:\n",
    "    examples = [json.loads(line) for line in f]\n",
    "\n",
    "entity_mapping = load_entities_mapping('Q_data.json')  # Update path if needed\n",
    "\n",
    "example = examples[0]\n",
    "masked_text, mapping = mask_entities(example['source'], example['entities'], entity_mapping)\n",
    "\n",
    "print(\"Masked Text:\", masked_text)\n",
    "print(\"Mapping:\", mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a10349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
