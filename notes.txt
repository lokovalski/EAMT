Katie MTG Notes
- Draft email to semeval people about data issues, small labeling problems 

TODOS:
Modify split funciton in main.py
- 80 10 10 split
Add model threshold of 0.7-0.8 score of predictions 
- only keep masked entities with score over that threshold
- raw number after preprocessing, number remaining post model
What to do with masking? 
- Convert to natural language?
- Might try reintegrating the translated entity prior to translation?
What is the baseline?
- zero shot send through translation system
- Report BLUE scores
- Sample 20 and do manual analysis --> compare to end to end model
- Fine tune model based on substitution or masking

stuff to address in final report:
- Dataset quality bad, concern about contamination and overfitting
- Want to hedge and say numbers are overinflated
- Test set is really small, concerned about conclusions 

------------------------------------------------------------------------------------------
Lola Work Notes 12/4

Finished ner_processing.py and updated main.py accordingly
- have not tested but should prob

------------------------------------------------------------------------------------------
Lola Work Notes 12/2:

TODO: 
- [COMPLETE] Split data into test,train in main 
- [COMPLETE] Update ner_processing.py with functions
- Fix masking to mask based on hugging face model predictions

Noticing some issues with the semeval data. They include fewer entities than the hugging face model identifies. 
- Treating the semeval data as truth but model predictions might be better

Performance issue: model takes a while to make a prediciton. Any way to parallelize and run on GPU?

------------------------------------------------------------------------------------------
Lola Work Notes 11/30:

STEP 1: CLEAN DATA/CREATE SOURCE OF TRUTH -- COMPLETE
Raw data being used: 'data/italian.jsonl','data/spanish.jsonl', 'data/mintaka,json'
- italian.jsonl and spanish.jsonl from SEMEVAL tasks
- mintaka.json from wikidata/mintaka dataset

Creates:
- 'data/spanish_updated.jsonl': fixes semeval mislabelling of all spanish entries as italian
- 'data/Q_data.json': Entity code extracted from mintaka (i.e. ["Q1153188": {"en": "Mount Lucania",...}])
        - key: entities
        - value: dictionary of translation in english, spanish, and italian
- 'spanish_w_labels.json': Contains English question, Spanish question, entity in english, entity in spanish
        - i.e. {"id": "2723bb1b", "source_locale": "es", "target_locale": "en", "source": 
        "Which actor was the star of Titanic and was born in Los Angeles, California?", "target": 
        "\u00bfQu\u00e9 actor protagoniz\u00f3 Titanic y naci\u00f3 en Los \u00c1ngeles, California?",
         "entities": {"Q65": {"es": "Los \u00c1ngeles", "en": "Los Angeles"}}, "from": "mintaka"}
- 'italian_w_labels.json': Same as spanish but in italian

STEP 2: NER AND ACURACY -- IN PROGRESS 
- Use tomaarsen/span-marker-mbert-base-multinerd model to find the non english entity in tranlated questions
  and compare to source of truth in 'spanish_w_labels.json' and 'italian_w_labels.json'


------------------------------------------------------------------------------------------
Katie Meeting Notes 11/19:
- Cascading errors: what if NER is really bad?
- Figure out accuracy in NER (if F1 is above 0.8 then that's fine, otherwise crash it)